- **平均精度（Average Precision, AP）**：
    
    - **AP** 是衡量目标检测模型性能的核心指标，它综合了模型在不同阈值下的精确度（Precision）和召回率（Recall）。
    - 计算方法通常是先计算每个类别的精确度-召回率曲线（Precision-Recall Curve），然后计算该曲线下的面积（Area Under Curve, AUC），这个面积值就是平均精度。
    - AP 值越高，表示模型在检测这个类别时的表现越好。
- **均值平均精度（Mean Average Precision, mAP）**：
    
    - **mAP** 是对所有类别 AP 的平均值。它能够综合评估模型在所有类别上的表现。
    - 在多类别检测任务中，mAP 是一个重要的综合性能指标，用于比较不同模型的整体效果。
- **精确度（Precision）**：
    
    - **Precision** 衡量的是模型预测为正例的样本中，实际为正例的比例。公式为： 
    $$Precison = \frac{TP}{TP+FP}$$
    - 在目标检测中，True Positives 是模型正确检测出的物体，False Positives 是模型错误地检测为物体的背景区域。
- **召回率（Recall）**：
    
    - **Recall** 衡量的是所有实际正例中，模型能够正确检测出的比例。公式为:
    $$Recall=\frac{TP}{TP+FN}$$
    - False Negatives 是那些被模型漏掉的实际物体。
- **F1 分数（F1 Score）**：
    
    - **F1 Score** 是精确度和召回率的调和平均数，综合考虑了两者的表现。公式为：
    $$F1 Score = 2\frac{Precison*Reacall}{Precision + Recall}$$
    - F1 分数在精确度和召回率之间权衡，适用于需要综合考虑这两个指标的场景。
    - 
- **IoU（Intersection over Union）**：
    
    - **IoU** 衡量预测框与真实框的重叠程度。计算公式为
    $$IoU=\frac{Area \ of \ Intersection}{Area \ of \ Union}$$
    - IoU 值用于确定一个预测框是否足够准确，通常设定一个阈值（例如 0.5），用于判断预测是否为真正的正例。
- **检测精度（Detection Precision）和检测召回率（Detection Recall）**：
    
    - **检测精度** 是指模型正确识别出的目标数量与所有识别出的目标数量之比。
    - **检测召回率** 是指模型正确识别出的目标数量与所有实际目标数量之比。
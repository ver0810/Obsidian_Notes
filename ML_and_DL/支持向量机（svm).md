## 支持向量机（support vector machine)
一种监督学习算法

## 逻辑回归
### 损失函数
$$min_\theta \frac{1}{m} \left[ \sum_{i=1}^m y^{(i)} (-\log h(0)(x^{(i)})) + (1-\log (1-h_0(x^{(i)})))\right]  + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2$$

## 高斯分布  
$$p(x^{(i)})=\mathcal N(x^{(i)};\mu, \sigma^2)$$

$$p(x^{(i)};\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp(-\frac{(x^{(i)} - \mu)^2}{2\sigma^2})$$
